# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: lr-model-meta.proto
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x13lr-model-meta.proto\x12&com.webank.ai.fate.core.mlmodel.buffer\" \n\x0bPredictMeta\x12\x11\n\tthreshold\x18\x01 \x01(\x01\"\xf6\x02\n\x0bLRModelMeta\x12\x0f\n\x07penalty\x18\x01 \x01(\t\x12\x0b\n\x03tol\x18\x02 \x01(\x01\x12\r\n\x05\x61lpha\x18\x03 \x01(\x01\x12\x11\n\toptimizer\x18\x04 \x01(\t\x12\x14\n\x0cparty_weight\x18\x05 \x01(\x01\x12\x12\n\nbatch_size\x18\x06 \x01(\x03\x12\x15\n\rlearning_rate\x18\x07 \x01(\x01\x12\x10\n\x08max_iter\x18\x08 \x01(\x03\x12\x12\n\nearly_stop\x18\t \x01(\t\x12\x1a\n\x12re_encrypt_batches\x18\n \x01(\x03\x12\x15\n\rfit_intercept\x18\x0b \x01(\x08\x12\x18\n\x10need_one_vs_rest\x18\x0c \x01(\x08\x12J\n\rpredict_param\x18\r \x01(\x0b\x32\x33.com.webank.ai.fate.core.mlmodel.buffer.PredictMeta\x12\x17\n\x0freveal_strategy\x18\x0e \x01(\t\x12\x0e\n\x06module\x18\x0f \x01(\tB\x12\x42\x10LRModelMetaProtob\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'lr_model_meta_pb2', _globals)
if _descriptor._USE_C_DESCRIPTORS == False:
  DESCRIPTOR._options = None
  DESCRIPTOR._serialized_options = b'B\020LRModelMetaProto'
  _globals['_PREDICTMETA']._serialized_start=63
  _globals['_PREDICTMETA']._serialized_end=95
  _globals['_LRMODELMETA']._serialized_start=98
  _globals['_LRMODELMETA']._serialized_end=472
# @@protoc_insertion_point(module_scope)
