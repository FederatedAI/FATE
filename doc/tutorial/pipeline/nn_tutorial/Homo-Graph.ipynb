{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homo-Graph Customized Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In FATE 1.10, we integrated Torch-geometric 2.2 into the FATE framework with which you can build Graph Neural Networks (GNN) in a homo federated way. Homo-graph is an extension of the customized model, but there are some differences in terms of input data and trainer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the installation please refer to [torch-geometric web site](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html), or run the following bash command in your terminal for quick installation.\n",
    "\n",
    "pip install pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.13.0+cpu.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cora Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cora is a graph dataset for multiple node classification. It has 2708 nodes and 10k edges. Each node has 1433 features. \n",
    "\n",
    "In federated homo graph modeling, each party holds their own graph dataset with the same features, i.e. horizontal federation. The nodes in the two graphs may not overlap and the parties do not exchange any information about their graph datasets duraing modeling.\n",
    "\n",
    "For simplicity, the host and the guest in the demo have the same Cora dataset. The train/validation/test is divided in the following way:\n",
    "\n",
    "train: [0:140]\n",
    "validation: [200:500]\n",
    "test: [500:1500]\n",
    "\n",
    "The preprocessed data can be find in examples/data/cora4fate which contains \"guest\" and \"host\" directory. both \"guest\" and \"host\" have feats.csv and adj.csv to store the node feature and adjacent matrix respectively. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSage Model\n",
    "\n",
    "Name the model code as homegraphsage.py. You can put it directly under federatedml/nn/model_zoo or use the shortcut interface of jupyter notebook to save it directly to federatedml/nn/model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.component.nn import save_to_fate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%save_to_fate model graphsage_cora.py\n",
    "\n",
    "import torch as t\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "import torch_geometric.nn as pyg\n",
    "\n",
    "\n",
    "class Sage(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, class_num):\n",
    "        super().__init__()\n",
    "        self.model = nn.ModuleList([\n",
    "            pyg.SAGEConv(in_channels=in_channels, out_channels=hidden_channels, project=True),\n",
    "            pyg.SAGEConv(in_channels=hidden_channels, out_channels=class_num),\n",
    "            nn.LogSoftmax()]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.model):\n",
    "            if isinstance(conv, pyg.SAGEConv):\n",
    "                x = conv(x, edge_index)\n",
    "            else:\n",
    "                x = conv(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homosage = Sage(in_channels=1433, hidden_channels=64, class_num=7)\n",
    "homosage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit a Homo-NN task with Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a pipeline and specifiy where the node feature and adjacent matrix file is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import os\n",
    "from torch import nn\n",
    "from pipeline import fate_torch_hook\n",
    "from pipeline.component.nn import TrainerParam\n",
    "from pipeline.backend.pipeline import PipeLine\n",
    "from pipeline.component import HomoNN, Evaluation\n",
    "from pipeline.component.reader import Reader\n",
    "from pipeline.interface import Data\n",
    "from pipeline.component.nn import DatasetParam\n",
    "\n",
    "fate_torch_hook(t)\n",
    "fate_project_path = os.getcwd() + \"/../../../../\"\n",
    "host = 10000\n",
    "guest = 9999\n",
    "arbiter = 10000\n",
    "pipeline = PipeLine().set_initiator(role='guest', party_id=guest).set_roles(guest=guest, host=host,\n",
    "                                                                        arbiter=arbiter)\n",
    "data_0 = {\"name\": \"cora_guest\", \"namespace\": \"experiment\"}\n",
    "data_1 = {\"name\": \"cora_host\", \"namespace\": \"experiment\"}\n",
    "\n",
    "data_path_0 = fate_project_path + 'examples/data/cora4fate/guest'\n",
    "data_path_1 = fate_project_path + 'examples/data/cora4fate/host'\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bind table and use the DatasetParam to specifiy the following parameters:\n",
    "1. id_col, name of the id column in csv, default 'id'\n",
    "2. label_col str, name of label column in csv, if None, will automatically take 'y' or 'label' or 'target' as label\n",
    "3. feature_dtype dtype of feature, supports int, long, float, double\n",
    "4. label_dtype: dtype of label, supports int, long, float, double\n",
    "5. feats_name: name of the node feature csv, default 'feats.csv'\n",
    "6. feats_dataset_col: name of the dataset column indicating to which dataset the node belongs, default 'dataset'\n",
    "7. feats_dataset_train: flag of the train set\n",
    "8. feats_dataset_vali: flag of the validation set\n",
    "9. feats_dataset_test: flag of the test set\n",
    "10. adj_name: name of the adjacent matrix, default 'adj.csv'\n",
    "11. adj_src_col: source node in the adjacent matrix, default 'node1'\n",
    "12. adj_dst_col: destination node in the adjacent matrix, default 'node2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.bind_table(name=data_0['name'], namespace=data_0['namespace'], path=data_path_0)\n",
    "pipeline.bind_table(name=data_1['name'], namespace=data_1['namespace'], path=data_path_1)\n",
    "\n",
    "reader_0 = Reader(name=\"reader_0\")\n",
    "reader_0.get_party_instance(role='guest', party_id=guest).component_param(table=data_0)\n",
    "reader_0.get_party_instance(role='host', party_id=host).component_param(table=data_1)\n",
    "dataset_param = DatasetParam(\n",
    "    \"graph\",\n",
    "    id_col='id',\n",
    "    label_col='y',\n",
    "    feature_dtype='float',\n",
    "    label_dtype='long',\n",
    "    feats_name='feats.csv',\n",
    "    feats_dataset_col='dataset',\n",
    "    feats_dataset_train='train',\n",
    "    feats_dataset_vali='vali',\n",
    "    feats_dataset_test='test',\n",
    "    adj_name='adj.csv',\n",
    "    adj_src_col='node1',\n",
    "    adj_dst_col='node2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup the model, loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = t.nn.Sequential(\n",
    "    t.nn.CustModel(module_name='graphsage_cora', class_name='Sage', in_channels=1433, hidden_channels=64, class_num=7)\n",
    ")\n",
    "loss = nn.NLLLoss()\n",
    "optimizer = t.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "homo_graph_0 = HomoNN(\n",
    "    name=\"homo_graph_0\",\n",
    "    model=model,\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    dataset=dataset_param,\n",
    "    trainer=TrainerParam(trainer_name='fedavg_graph_trainer', epochs=10, batch_size=10,\n",
    "                            validation_freqs=1, num_neighbors=[11, 11], task_type='multi'),\n",
    "    torch_seed=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate every component together and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.add_component(reader_0)\n",
    "pipeline.add_component(homo_graph_0, data=Data(train_data=reader_0.output.data))\n",
    "pipeline.add_component(Evaluation(name='eval_0', eval_type='multi'), data=Data(data=homo_graph_0.output.data))\n",
    "\n",
    "pipeline.compile()\n",
    "pipeline.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6014097d4fbe68b982926f809650a6d6f12d367fa066105c39b397ad90be87cf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
