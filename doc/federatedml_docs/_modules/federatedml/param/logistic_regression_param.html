

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>federatedml.param.logistic_regression_param &mdash; FATE 1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> FATE
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"></div>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">FATE</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>federatedml.param.logistic_regression_param</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for federatedml.param.logistic_regression_param</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python</span>
<span class="c1"># -*- coding: utf-8 -*-</span>

<span class="c1">#</span>
<span class="c1">#  Copyright 2019 The FATE Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1">#  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1">#  you may not use this file except in compliance with the License.</span>
<span class="c1">#  You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#      http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1">#  Unless required by applicable law or agreed to in writing, software</span>
<span class="c1">#  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1">#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1">#  See the License for the specific language governing permissions and</span>
<span class="c1">#  limitations under the License.</span>
<span class="c1">#</span>
<span class="kn">import</span> <span class="nn">copy</span>

<span class="kn">from</span> <span class="nn">federatedml.param.base_param</span> <span class="k">import</span> <span class="n">BaseParam</span>
<span class="kn">from</span> <span class="nn">federatedml.param.encrypt_param</span> <span class="k">import</span> <span class="n">EncryptParam</span>
<span class="kn">from</span> <span class="nn">federatedml.param.encrypted_mode_calculation_param</span> <span class="k">import</span> <span class="n">EncryptedModeCalculatorParam</span>
<span class="kn">from</span> <span class="nn">federatedml.param.predict_param</span> <span class="k">import</span> <span class="n">PredictParam</span>
<span class="kn">from</span> <span class="nn">federatedml.param.cross_validation_param</span> <span class="k">import</span> <span class="n">CrossValidationParam</span>
<span class="kn">from</span> <span class="nn">federatedml.util</span> <span class="k">import</span> <span class="n">consts</span>


<div class="viewcode-block" id="InitParam"><a class="viewcode-back" href="../../../federatedml.param.html#federatedml.param.logistic_regression_param.InitParam">[docs]</a><span class="k">class</span> <span class="nc">InitParam</span><span class="p">(</span><span class="n">BaseParam</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize Parameters used in initializing a model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    init_method : str, &#39;random_uniform&#39;, &#39;random_normal&#39;, &#39;ones&#39;, &#39;zeros&#39; or &#39;const&#39;. default: &#39;random_uniform&#39;</span>
<span class="sd">        Initial method.</span>

<span class="sd">    init_const : int or float, default: 1</span>
<span class="sd">        Required when init_method is &#39;const&#39;. Specify the constant.</span>

<span class="sd">    fit_intercept : bool, default: True</span>
<span class="sd">        Whether to initialize the intercept or not.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_method</span><span class="o">=</span><span class="s1">&#39;random_uniform&#39;</span><span class="p">,</span> <span class="n">init_const</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_method</span> <span class="o">=</span> <span class="n">init_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_const</span> <span class="o">=</span> <span class="n">init_const</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span> <span class="o">=</span> <span class="n">fit_intercept</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span> <span class="o">=</span> <span class="n">random_seed</span>

<div class="viewcode-block" id="InitParam.check"><a class="viewcode-back" href="../../../federatedml.param.html#federatedml.param.logistic_regression_param.InitParam.check">[docs]</a>    <span class="k">def</span> <span class="nf">check</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_method</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">!=</span> <span class="s2">&quot;str&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Init param&#39;s init_method </span><span class="si">{}</span><span class="s2"> not supported, should be str type&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_method</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">init_method</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_method</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;random_uniform&#39;</span><span class="p">,</span> <span class="s1">&#39;random_normal&#39;</span><span class="p">,</span> <span class="s1">&#39;ones&#39;</span><span class="p">,</span> <span class="s1">&#39;zeros&#39;</span><span class="p">,</span> <span class="s1">&#39;const&#39;</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Init param&#39;s init_method </span><span class="si">{}</span><span class="s2"> not supported, init_method should in &#39;random_uniform&#39;,&quot;</span>
                    <span class="s2">&quot; &#39;random_normal&#39; &#39;ones&#39;, &#39;zeros&#39; or &#39;const&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_method</span><span class="p">))</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_const</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;int&#39;</span><span class="p">,</span> <span class="s1">&#39;float&#39;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Init param&#39;s init_const </span><span class="si">{}</span><span class="s2"> not supported, should be int or float type&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_const</span><span class="p">))</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">!=</span> <span class="s1">&#39;bool&#39;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Init param&#39;s fit_intercept </span><span class="si">{}</span><span class="s2"> not supported, should be bool type&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;int&#39;</span><span class="p">,</span> <span class="s1">&#39;float&#39;</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Init param&#39;s random_seed </span><span class="si">{}</span><span class="s2"> not supported, should be int or float type&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="p">))</span>

        <span class="k">return</span> <span class="kc">True</span></div></div>


<div class="viewcode-block" id="LogisticParam"><a class="viewcode-back" href="../../../federatedml.param.html#federatedml.param.logistic_regression_param.LogisticParam">[docs]</a><span class="k">class</span> <span class="nc">LogisticParam</span><span class="p">(</span><span class="n">BaseParam</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters used for Logistic Regression both for Homo mode or Hetero mode.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    penalty : str, &#39;L1&#39; or &#39;L2&#39;. default: &#39;L2&#39;</span>
<span class="sd">        Penalty method used in LR. Please note that, when using encrypted version in HomoLR,</span>
<span class="sd">        &#39;L1&#39; is not supported.</span>

<span class="sd">    eps : float, default: 1e-5</span>
<span class="sd">        The tolerance of convergence</span>

<span class="sd">    alpha : float, default: 1.0</span>
<span class="sd">        Regularization strength coefficient.</span>

<span class="sd">    optimizer : str, &#39;sgd&#39;, &#39;rmsprop&#39;, &#39;adam&#39; or &#39;adagrad&#39;, default: &#39;sgd&#39;</span>
<span class="sd">        Optimize method</span>

<span class="sd">    party_weight : int or float, default: 1</span>
<span class="sd">        Required in Homo LR. Setting the weight of model updated for this party.</span>
<span class="sd">        The higher weight set, the higher influence made for this party when updating model.</span>

<span class="sd">    batch_size : int, default: -1</span>
<span class="sd">        Batch size when updating model. -1 means use all data in a batch. i.e. Not to use mini-batch strategy.</span>

<span class="sd">    learning_rate : float, default: 0.01</span>
<span class="sd">        Learning rate</span>

<span class="sd">    max_iter : int, default: 100</span>
<span class="sd">        The maximum iteration for training.</span>

<span class="sd">    converge_func : str, &#39;diff&#39; or &#39;abs&#39;, default: &#39;diff&#39;</span>
<span class="sd">        Method used to judge converge or not.</span>
<span class="sd">            a)	diffï¼š Use difference of loss between two iterations to judge whether converge.</span>
<span class="sd">            b)	abs: Use the absolute value of loss to judge whether converge. i.e. if loss &lt; eps, it is converged.</span>

<span class="sd">    re_encrypt_batches : int, default: 2</span>
<span class="sd">        Required when using encrypted version HomoLR. Since multiple batch updating coefficient may cause</span>
<span class="sd">        overflow error. The model need to be re-encrypt for every several batches. Please be careful when setting</span>
<span class="sd">        this parameter. Too large batches may cause training failure.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;L2&#39;</span><span class="p">,</span>
                 <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;sgd&#39;</span><span class="p">,</span> <span class="n">party_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">batch_size</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">init_param</span><span class="o">=</span><span class="n">InitParam</span><span class="p">(),</span>
                 <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">converge_func</span><span class="o">=</span><span class="s1">&#39;diff&#39;</span><span class="p">,</span>
                 <span class="n">encrypt_param</span><span class="o">=</span><span class="n">EncryptParam</span><span class="p">(),</span> <span class="n">re_encrypt_batches</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                 <span class="n">encrypted_mode_calculator_param</span><span class="o">=</span><span class="n">EncryptedModeCalculatorParam</span><span class="p">(),</span>
                 <span class="n">need_run</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">predict_param</span><span class="o">=</span><span class="n">PredictParam</span><span class="p">(),</span> <span class="n">cv_param</span><span class="o">=</span><span class="n">CrossValidationParam</span><span class="p">()):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LogisticParam</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">penalty</span> <span class="o">=</span> <span class="n">penalty</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_param</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">init_param</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">converge_func</span> <span class="o">=</span> <span class="n">converge_func</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encrypt_param</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">encrypt_param</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">re_encrypt_batches</span> <span class="o">=</span> <span class="n">re_encrypt_batches</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">party_weight</span> <span class="o">=</span> <span class="n">party_weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encrypted_mode_calculator_param</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">encrypted_mode_calculator_param</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">need_run</span> <span class="o">=</span> <span class="n">need_run</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predict_param</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">predict_param</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv_param</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">cv_param</span><span class="p">)</span>

<div class="viewcode-block" id="LogisticParam.check"><a class="viewcode-back" href="../../../federatedml.param.html#federatedml.param.logistic_regression_param.LogisticParam.check">[docs]</a>    <span class="k">def</span> <span class="nf">check</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">descr</span> <span class="o">=</span> <span class="s2">&quot;logistic_param&#39;s&quot;</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">penalty</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">!=</span> <span class="s2">&quot;str&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;logistic_param&#39;s penalty </span><span class="si">{}</span><span class="s2"> not supported, should be str type&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">penalty</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">penalty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalty</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalty</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;L1&#39;</span><span class="p">,</span> <span class="s1">&#39;L2&#39;</span><span class="p">,</span> <span class="s1">&#39;NONE&#39;</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;logistic_param&#39;s penalty not supported, penalty should be &#39;L1&#39;, &#39;L2&#39; or &#39;none&#39;&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">!=</span> <span class="s2">&quot;float&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;logistic_param&#39;s eps </span><span class="si">{}</span><span class="s2"> not supported, should be float type&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">))</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">!=</span> <span class="s2">&quot;float&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;logistic_param&#39;s alpha </span><span class="si">{}</span><span class="s2"> not supported, should be float type&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">))</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">!=</span> <span class="s2">&quot;str&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;logistic_param&#39;s optimizer </span><span class="si">{}</span><span class="s2"> not supported, should be str type&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;sgd&#39;</span><span class="p">,</span> <span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="s1">&#39;adagrad&#39;</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;logistic_param&#39;s optimizer not supported, optimizer should be&quot;</span>
                    <span class="s2">&quot; &#39;sgd&#39;, &#39;rmsprop&#39;, &#39;adam&#39; or &#39;adagrad&#39;&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">!=</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;logistic_param&#39;s batch_size </span><span class="si">{}</span><span class="s2"> not supported, should be int type&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="s2">&quot;long&quot;</span><span class="p">]</span> \
                    <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">&lt;</span> <span class="n">consts</span><span class="o">.</span><span class="n">MIN_BATCH_SIZE</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">descr</span> <span class="o">+</span> <span class="s2">&quot; </span><span class="si">{}</span><span class="s2"> not supported, should be larger than 10 or &quot;</span>
                                         <span class="s2">&quot;-1 represent for all data&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">))</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">!=</span> <span class="s2">&quot;float&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;logistic_param&#39;s learning_rate </span><span class="si">{}</span><span class="s2"> not supported, should be float type&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">init_param</span><span class="o">.</span><span class="n">check</span><span class="p">()</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">!=</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;logistic_param&#39;s max_iter </span><span class="si">{}</span><span class="s2"> not supported, should be int type&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">))</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;logistic_param&#39;s max_iter must be greater or equal to 1&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">converge_func</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">!=</span> <span class="s2">&quot;str&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;logistic_param&#39;s converge_func </span><span class="si">{}</span><span class="s2"> not supported, should be str type&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">converge_func</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">converge_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">converge_func</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">converge_func</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;diff&#39;</span><span class="p">,</span> <span class="s1">&#39;abs&#39;</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;logistic_param&#39;s converge_func not supported, converge_func should be&quot;</span>
                    <span class="s2">&quot; &#39;diff&#39; or &#39;abs&#39;&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">encrypt_param</span><span class="o">.</span><span class="n">check</span><span class="p">()</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">re_encrypt_batches</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">!=</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;logistic_param&#39;s re_encrypt_batches </span><span class="si">{}</span><span class="s2"> not supported, should be int type&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">re_encrypt_batches</span><span class="p">))</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">re_encrypt_batches</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;logistic_param&#39;s re_encrypt_batches must be greater or equal to 0&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">party_weight</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="s1">&#39;float&#39;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;logistic_param&#39;s party_weight </span><span class="si">{}</span><span class="s2"> not supported, should be &#39;int&#39; or &#39;float&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">party_weight</span><span class="p">))</span>
        <span class="k">return</span> <span class="kc">True</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, FATE_TEAM

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>