{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a982d9b",
   "metadata": {},
   "source": [
    "# Homo NN MNIST图像分类: 介绍数据集与模型自定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b31519",
   "metadata": {},
   "source": [
    "在该版本中 整个nn的架构有很大的调整，nn模块开发了dataset与model_zoo模块，旨在提供数据集和模型的自定义功能，在这个教程中， 我们将会介绍nn的Dataset机制，以及介绍如何进行模型自定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e255e886",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57e6ec",
   "metadata": {},
   "source": [
    "在 FATE-1.10中，FATE基于pytorch的Dataset类开发一个新的Dataset基类，用户可以基于这个类，实现\\_\\_getitem\\_\\_, \\_\\_len\\_\\_, load接口，\n",
    "load接口接收一个地址，可以从本地读取数据。当提交任务时，可以通过reader组件输入数据地址，HomoNN会使用用户指定的Dataset，使用load接口读取数据，使用数据集进行训练\n",
    "\n",
    "在FATE-1.10中，提供了table, nlp_tokenizer, image三种数据集，以满足基本的使用需要，但是用户可以随意自定义自己的dataset，dataset的自定义将会在下一教程介绍\n",
    "\n",
    "### TableDataset\n",
    "table.py下提供了TableDataset, 用于处理csv格式的数据，并会自动从数据中解析id和label，此处展示部分源代码，可见该数据集的参数使用:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80fa81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableDataset(Dataset):\n",
    "\n",
    "    \"\"\"\n",
    "     A Table Dataset, load data from a give csv path, or transform FATE DTable\n",
    "\n",
    "     Parameters\n",
    "     ----------\n",
    "     label_col str, name of label column in csv, if None, will automatically take 'y' or 'label' or 'target' as label\n",
    "     feature_dtype dtype of feature, supports int, long, float, double\n",
    "     label_dtype: dtype of label, supports int, long, float, double\n",
    "     label_shape: list or tuple, the shape of label\n",
    "     flatten_label: bool, flatten extracted label column or not, default is False\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, label_col=None, feature_dtype='float', label_dtype='float', label_shape=None,\n",
    "                 flatten_label=False):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b44382",
   "metadata": {},
   "source": [
    "### TokenizerDataset\n",
    "\n",
    "nlp_tokenizer.py下提供了TokenizerDataset，基于transformer的BertTokenizer开发，可以从csv里读取字符串，并同时对文本进行自动分词，转换为词id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c41c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizerDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A Dataset for some basic NLP Tasks, this dataset will automatically transform raw text into word indices\n",
    "    using BertTokenizer from transformers library,\n",
    "    see https://huggingface.co/docs/transformers/model_doc/bert?highlight=berttokenizer for details of BertTokenizer\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    truncation bool, truncate word sequence to 'text_max_length'\n",
    "    text_max_length int, max length of word sequences\n",
    "    tokenizer_name_or_path str, name of bert tokenizer(see transformers official for details) or path to local\n",
    "                                transformer tokenizer folder\n",
    "    return_label bool, return label or not, this option is for host dataset, when running hetero-NN\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, truncation=True, text_max_length=128,\n",
    "                 tokenizer_name_or_path=\"bert-base-uncased\",\n",
    "                 return_label=True):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b348177",
   "metadata": {},
   "source": [
    "### ImageDataset\n",
    "image.py下提供了ImageDataset, 用于简单地处理图像数据，它基于torchvision的ImageFolder开发，可见该数据集的参数使用:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571eed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    A basic Image Dataset built on pytorch ImageFolder, supports simple image transform\n",
    "    Given a folder path, ImageDataset will load images from this folder, images in this\n",
    "    folder need to be organized in a Torch-ImageFolder format, see\n",
    "    https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html for details.\n",
    "\n",
    "    Image name will be automatically taken as the sample id.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    center_crop : bool, use center crop transformer\n",
    "    center_crop_shape: tuple or list\n",
    "    generate_id_from_file_name: bool, whether to take image name as sample id\n",
    "    file_suffix: str, default is '.jpg', if generate_id_from_file_name is True, will remove this suffix from file name,\n",
    "                 result will be the sample id\n",
    "    return_label: bool, return label or not, this option is for host dataset, when running hetero-NN\n",
    "    float64: bool, returned image tensors will be transformed to double precision\n",
    "    label_dtype: str, long, float, or double, the dtype of return label\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, center_crop=False, center_crop_shape=None,\n",
    "                 generate_id_from_file_name=True, file_suffix='.jpg',\n",
    "                 return_label=True, float64=False, label_dtype='long'):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ae1e2",
   "metadata": {},
   "source": [
    "本次教程，我们介绍image数据集，它基于pytorch的ImageFolder类开发"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c6b20",
   "metadata": {},
   "source": [
    "### ImageDataset使用\n",
    "此处 我们用ImageDataset来加载MNIST数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0000f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federatedml.nn.dataset.image import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28fcd702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  1  2  3  4  5  6  7\t8  9\r\n"
     ]
    }
   ],
   "source": [
    "# 查看mnist数据集文件夹结构，一共10个文件夹，每个文件夹下放有各个类图像，使用方式与ImageFolder一致\n",
    "! ls ../examples/data/mnist_folder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf4d85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset()\n",
    "dataset.load('../examples/data/mnist/') # 读取mnist数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a558125e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fdd37eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0275, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0118, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.0275, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0118, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.0275, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0118, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]),\n",
       " tensor(3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[400] # 查看图像 与ImageFolder使用方式一致"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a3a2d",
   "metadata": {},
   "source": [
    "## 自定义模型\n",
    "\n",
    "在 FATE-1.10中，FATE可以通过pipeline提交pytorch Sequential模型.然而，Sequential结合pytorch自带的layer, 还是无法表示更为复杂的模型\n",
    "\n",
    "因此，FATE-1.10中加入了model_zoo模块，位于federatedml.nn.model_zoo下。现在，你可以定制自己的pytorch模型，**前提是这个模型必须是基于t.nn.Module开发，并实现了forward接口**. 将你实现好的模型文件放入federatedml/nn/model_zoo下, 在提交任务时通过接口指定该模块，homo-nn会自动搜寻并导入你实现的模型\n",
    "\n",
    "这里，为了完成MNIST分类任务，我们先本地编写一个带有卷积网络的NN模块:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "898046e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch as t\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class ImgNet(nn.Module):\n",
    "    def __init__(self, class_num=10):\n",
    "        super(ImgNet, self).__init__()\n",
    "        self.seq = t.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3),\n",
    "            nn.AvgPool2d(kernel_size=3)\n",
    "        )\n",
    "        \n",
    "        self.fc = t.nn.Sequential(\n",
    "            nn.Linear(48, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, class_num)\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.fc(x)\n",
    "        if self.training:\n",
    "            return x\n",
    "        else:\n",
    "            return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "081c727b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImgNet(\n",
       "  (seq): Sequential(\n",
       "    (0): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): AvgPool2d(kernel_size=3, stride=3, padding=0)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=48, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_model = ImgNet(10)\n",
    "img_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e799b0cc",
   "metadata": {},
   "source": [
    "将模型代码命名为image_net.py，可以直接把它放在federatedml/nn/model_zoo下\n",
    "\n",
    "或者使用jupyter notebook的快捷接口 直接将其保存到federatedml/nn/model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8207004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.component.nn import save_to_fate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f972ba9f",
   "metadata": {},
   "source": [
    "## jupyter保存接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ce623",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%save_to_fate model image_net.py\n",
    "from torch import nn\n",
    "import torch as t\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class ImgNet(nn.Module):\n",
    "    def __init__(self, class_num=10):\n",
    "        super(ImgNet, self).__init__()\n",
    "        self.seq = t.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3),\n",
    "            nn.AvgPool2d(kernel_size=3)\n",
    "        )\n",
    "        \n",
    "        self.fc = t.nn.Sequential(\n",
    "            nn.Linear(48, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, class_num)\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.fc(x)\n",
    "        if self.training:\n",
    "            return x\n",
    "        else:\n",
    "            return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "749d50b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from torch import nn\r\n",
      "import torch as t\r\n",
      "from torch.nn import functional as F\r\n",
      "\r\n",
      "class ImgNet(nn.Module):\r\n",
      "    def __init__(self, class_num=10):\r\n",
      "        super(ImgNet, self).__init__()\r\n",
      "        self.seq = t.nn.Sequential(\r\n",
      "            nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5),\r\n",
      "            nn.MaxPool2d(kernel_size=3),\r\n",
      "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3),\r\n",
      "            nn.AvgPool2d(kernel_size=3)\r\n",
      "        )\r\n",
      "        \r\n",
      "        self.fc = t.nn.Sequential(\r\n",
      "            nn.Linear(48, 32),\r\n",
      "            nn.ReLU(),\r\n",
      "            nn.Linear(32, class_num)\r\n",
      "        )\r\n",
      "        self.softmax = nn.Softmax(dim=1)\r\n",
      "\r\n",
      "    def forward(self, x):\r\n",
      "        x = self.seq(x)\r\n",
      "        x = x.flatten(start_dim=1)\r\n",
      "        x = self.fc(x)\r\n",
      "        if self.training:\r\n",
      "            return x\r\n",
      "        else:\r\n",
      "            return self.softmax(x)\r\n"
     ]
    }
   ],
   "source": [
    "! cat ../fate/python/federatedml/nn/model_zoo/image_net.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0311ed01",
   "metadata": {},
   "source": [
    "## 进行本地测试\n",
    "\n",
    "我们可以先不急着提交任务，可以使用Trainer进行本地测试。上个教程提到，fate自带一个FedAVGTrainer\n",
    "\n",
    "我们可以使用我们的数据集，自定义的模型，和Trainer进行本地调试，测试是否能够跑通程序\n",
    "**本地测试的情况下，会跳过所有联邦流程，模型不会进行fed averaging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c53366f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federatedml.nn.homo.trainer.fedavg_trainer import FedAVGTrainer\n",
    "trainer = FedAVGTrainer(epochs=3, batch_size=256, shuffle=True, data_loader_worker=8) # 参数\n",
    "trainer.set_model(img_model) # 设置自定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "711ef7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.local_mode() # !! 请务必启用local_mode以跳过联邦流程 !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d65f9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch is 0\n",
      "epoch loss is 2.6494100991781657\n",
      "epoch is 1\n",
      "epoch loss is 2.1795332801533256\n",
      "epoch is 2\n",
      "epoch loss is 1.5566089883662981\n"
     ]
    }
   ],
   "source": [
    "optimizer = t.optim.Adam(img_model.parameters(), lr=0.01)\n",
    "loss = t.nn.CrossEntropyLoss()\n",
    "trainer.train(train_set=dataset,optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08ed729",
   "metadata": {},
   "source": [
    "可以跑通！那我们可以提交联邦任务了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413aefa9",
   "metadata": {},
   "source": [
    "## 提交使用自定义模型的Homo-NN任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1518af62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch' from '/home/cwj/standalone_fate_install_1.9.0_release/env/python/venv/lib/python3.8/site-packages/torch/__init__.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as t\n",
    "from torch import nn\n",
    "from pipeline import fate_torch_hook\n",
    "from pipeline.component import HomoNN\n",
    "from pipeline.backend.pipeline import PipeLine\n",
    "from pipeline.component import Reader, Evaluation, DataTransform\n",
    "from pipeline.interface import Data, Model\n",
    "\n",
    "fate_torch_hook(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d900c35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': 'experiment', 'table_name': 'mnist_host_1'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# 绑定地址到fate name&namespace\n",
    "fate_project_path = os.path.abspath('../')\n",
    "host_0 = 10000\n",
    "host_1 = 9999\n",
    "pipeline = PipeLine().set_initiator(role='host', party_id=host_0).set_roles(host=[host_0, host_1],\n",
    "                                                                            arbiter=[host_0])\n",
    "\n",
    "data_0 = {\"name\": \"mnist_host_0\", \"namespace\": \"experiment\"}\n",
    "data_1 = {\"name\": \"mnist_host_1\", \"namespace\": \"experiment\"}\n",
    "\n",
    "# 为方便，本示例中两个client使用同一份数据集\n",
    "data_path_0 = fate_project_path + '/examples/data/mnist'\n",
    "data_path_1 = fate_project_path + '/examples/data/mnist'\n",
    "pipeline.bind_table(name=data_0['name'], namespace=data_0['namespace'], path=data_path_0)\n",
    "pipeline.bind_table(name=data_1['name'], namespace=data_1['namespace'], path=data_path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3af79ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义reader\n",
    "reader_0 = Reader(name=\"reader_0\")\n",
    "reader_0.get_party_instance(role='host', party_id=host_0).component_param(table=data_0)\n",
    "reader_0.get_party_instance(role='host', party_id=host_1).component_param(table=data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de9917a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.component.homo_nn import DatasetParam, TrainerParam  # 数据集的接口\n",
    "from pipeline.component.nn.backend.torch.cust_model import CustModel  # 自定义模型的接口\n",
    "\n",
    "model = t.nn.Sequential(\n",
    "    t.nn.CustModel(module_name='image_net', class_name='ImgNet', class_num=10) \n",
    "    # module_name指定自定义模型的模块名，class_name指定你自定义的类, name之外的参数将会被传递到模型的__init__上，比如\n",
    "    # 此处的class_num\n",
    ")\n",
    "\n",
    "nn_component = HomoNN(name='nn_0',\n",
    "                      model=model, # 模型\n",
    "                      loss=t.nn.CrossEntropyLoss(),\n",
    "                      optimizer=t.optim.Adam(model.parameters(), lr=0.01),\n",
    "                      dataset=DatasetParam(dataset_name='image'),  # 使用image dataset\n",
    "                      trainer=TrainerParam(trainer_name='fedavg_trainer', epochs=3, batch_size=256, validation_freqs=1),\n",
    "                      torch_seed=100 # 全局随机种子\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62361f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pipeline.backend.pipeline.PipeLine at 0x7f54843f3a30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 添加组件到pipeline，定义数据IO关系，提交即可\n",
    "pipeline.add_component(reader_0)\n",
    "pipeline.add_component(nn_component, data=Data(train_data=reader_0.output.data))\n",
    "pipeline.add_component(Evaluation(name='eval_0', eval_type='multi'), data=Data(data=nn_component.output.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fa46219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-11-14 11:48:02.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mJob id is 202211141148018430020\n",
      "\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:02.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:00\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:03.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:01\u001b[0m\n",
      "\u001b[0mm2022-11-14 11:48:04.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2022-11-14 11:48:04.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:02\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:05.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:03\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:06.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:04\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:07.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:05\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:08.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:06\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:10.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:07\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:11.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:08\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:12.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:09\u001b[0m\n",
      "\u001b[0mm2022-11-14 11:48:13.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2022-11-14 11:48:13.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:10\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:14.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:11\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:15.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:12\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:16.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:13\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:17.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:14\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:18.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:16\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:19.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:17\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:20.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:18\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:21.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:19\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:22.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:20\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:23.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:21\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:24.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:22\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:26.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:23\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:27.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:24\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:28.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:25\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:29.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:26\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:30.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:27\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:31.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:29\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:32.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:30\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:33.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:31\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:34.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:32\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:35.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:33\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:36.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:34\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:38.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:35\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:39.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:36\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:40.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:37\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:41.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:38\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-11-14 11:48:42.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:39\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:43.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:41\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:44.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:42\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:45.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:43\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:46.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:44\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:47.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:45\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:48.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:46\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:49.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:47\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:50.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:48\u001b[0m\n",
      "\u001b[0mm2022-11-14 11:48:52.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2022-11-14 11:48:52.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:00:49\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:53.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:00:50\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:54.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:00:51\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:55.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:00:52\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:56.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:00:53\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:57.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:00:54\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:58.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:00:55\u001b[0m\n",
      "\u001b[32m2022-11-14 11:48:59.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:00:57\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:00.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:00:58\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:01.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:00:59\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:03.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mJob is success!!! Job id is 202211141148018430020\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:03.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTotal time: 0:01:01\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pipeline.compile()\n",
    "pipeline.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5734f3",
   "metadata": {},
   "source": [
    "成功了！并且 我们可以用同样的方式，为任务加一个验证集，看看效果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3897be2",
   "metadata": {},
   "source": [
    "## 提交使用自定义模型的Homo-NN任务 + 验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac41557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-11-14 11:49:07.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mJob id is 202211141149044102230\n",
      "\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:07.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:00\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:08.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:01\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:10.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:02\u001b[0m\n",
      "\u001b[0mm2022-11-14 11:49:11.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2022-11-14 11:49:11.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:03\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:12.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:04\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:13.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:05\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:14.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:06\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:15.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:07\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:16.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:08\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:17.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:09\u001b[0m\n",
      "\u001b[0mm2022-11-14 11:49:19.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2022-11-14 11:49:19.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:11\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:20.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:12\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:21.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:13\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:22.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:14\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:23.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:16\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:24.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:17\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:25.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:18\u001b[0m\n",
      "\u001b[0mm2022-11-14 11:49:27.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2022-11-14 11:49:27.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:20\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:29.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:21\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:30.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:22\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:31.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:23\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:32.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:24\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:33.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:25\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:34.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:26\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:35.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:27\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:36.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:28\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:37.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:29\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:38.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:31\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:39.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:32\u001b[0m\n",
      "\u001b[32m2022-11-14 11:49:41.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:33\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "from torch import nn\n",
    "from pipeline import fate_torch_hook\n",
    "from pipeline.component import HomoNN\n",
    "from pipeline.backend.pipeline import PipeLine\n",
    "from pipeline.component import Reader, Evaluation, DataTransform\n",
    "from pipeline.interface import Data, Model\n",
    "\n",
    "fate_torch_hook(t)\n",
    "\n",
    "import os\n",
    "# 绑定地址到fate name&namespace\n",
    "fate_project_path = os.path.abspath('../')\n",
    "host_0 = 10000\n",
    "host_1 = 9999\n",
    "pipeline = PipeLine().set_initiator(role='host', party_id=host_0).set_roles(host=[host_0, host_1],\n",
    "                                                                            arbiter=[host_0])\n",
    "\n",
    "validate_data = {\"name\": \"mnist_validate\", \"namespace\": \"experiment\"}\n",
    "\n",
    "# 为方便，本示例中两个client使用同一份数据集\n",
    "data_path_val = fate_project_path + '/examples/data/mnist_val'\n",
    "pipeline.bind_table(name=validate_data['name'], namespace=validate_data['namespace'], path=data_path_val)\n",
    "\n",
    "# 定义reader\n",
    "reader_0 = Reader(name=\"reader_0\")\n",
    "reader_0.get_party_instance(role='host', party_id=host_0).component_param(table=data_0)\n",
    "reader_0.get_party_instance(role='host', party_id=host_1).component_param(table=data_1)\n",
    "# validate data\n",
    "reader_1 = Reader(name=\"reader_1\")\n",
    "reader_1.get_party_instance(role='host', party_id=host_0).component_param(table=validate_data)\n",
    "reader_1.get_party_instance(role='host', party_id=host_1).component_param(table=validate_data)\n",
    "\n",
    "from pipeline.component.homo_nn import DatasetParam, TrainerParam  # 数据集的接口\n",
    "from pipeline.component.nn.backend.torch.cust_model import CustModel  # 自定义模型的接口\n",
    "\n",
    "model = t.nn.Sequential(\n",
    "     t.nn.CustModel(module_name='image_net', class_name='ImgNet', class_num=10) \n",
    "    # module_name指定自定义模型的模块名，class_name指定你自定义的类, name之外的参数将会被传递到模型的__init__上，比如\n",
    "    # 此处的class_num\n",
    ")\n",
    "\n",
    "nn_component = HomoNN(name='nn_0',\n",
    "                      model=model, # 模型\n",
    "                      loss=t.nn.CrossEntropyLoss(),\n",
    "                      optimizer=t.optim.Adam(model.parameters(), lr=0.01),\n",
    "                      dataset=DatasetParam(dataset_name='image'),  # 使用image dataset\n",
    "                      trainer=TrainerParam(trainer_name='fedavg_trainer', epochs=3, batch_size=256, validation_freqs=1),\n",
    "                      torch_seed=100 # 全局随机种子\n",
    "                      )\n",
    "\n",
    "# 添加组件到pipeline，定义数据IO关系，提交即可\n",
    "pipeline.add_component(reader_0)\n",
    "pipeline.add_component(reader_1)\n",
    "pipeline.add_component(nn_component, data=Data(train_data=reader_0.output.data, validate_data=reader_1.output.data))\n",
    "pipeline.add_component(Evaluation(name='eval_0', eval_type='multi'), data=Data(data=nn_component.output.data))\n",
    "pipeline.compile()\n",
    "pipeline.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
