{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a982d9b",
   "metadata": {},
   "source": [
    "# Homo NN MNIST图像分类: 介绍数据集与模型自定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b31519",
   "metadata": {},
   "source": [
    "在该版本中 整个nn的架构有很大的调整，nn模块开发了dataset与model_zoo模块，旨在提供数据集和模型的自定义功能，在这个教程中， 我们将会介绍nn的Dataset机制，以及介绍如何进行模型自定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e255e886",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57e6ec",
   "metadata": {},
   "source": [
    "在 FATE-1.10中，FATE基于pytorch的Dataset类开发一个新的Dataset基类，用户可以基于这个类，实现\\_\\_getitem\\_\\_, \\_\\_len\\_\\_, load接口，\n",
    "load接口接收一个地址，可以从本地读取数据。当提交任务时，可以通过reader组件输入数据地址，HomoNN会使用用户指定的Dataset，使用load接口读取数据，使用数据集进行训练\n",
    "\n",
    "在FATE-1.10中，提供了table, nlp_tokenizer, image三种数据集，以满足基本的使用需要，但是用户可以随意自定义自己的dataset，dataset的自定义将会在下一教程介绍\n",
    "\n",
    "本次教程，我们介绍image数据集，它基于pytorch的ImageFolder类开发"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c6b20",
   "metadata": {},
   "source": [
    "### ImageDataset\n",
    "此处 我们用ImageDataset来加载MNIST数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0000f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federatedml.nn.dataset.image import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28fcd702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  1  2  3  4  5  6  7\t8  9\r\n"
     ]
    }
   ],
   "source": [
    "# 查看mnist数据集文件夹结构，一共10个文件夹，每个文件夹下放有各个类图像，使用方式与ImageFolder一致\n",
    "! ls ../examples/data/mnist_folder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf4d85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset()\n",
    "dataset.load('../examples/data/mnist/') # 读取mnist数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a558125e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fdd37eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0275, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0118, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.0275, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0118, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.0275, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0118, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]),\n",
       " tensor(3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[400] # 查看图像 与ImageFolder使用方式一致"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a3a2d",
   "metadata": {},
   "source": [
    "## 自定义模型\n",
    "\n",
    "在 FATE-1.10中，FATE可以通过pipeline提交pytorch Sequential模型.然而，Sequential结合pytorch自带的layer, 还是无法表示更为复杂的模型\n",
    "\n",
    "因此，FATE-1.10中加入了model_zoo模块，位于federatedml.nn.model_zoo下。现在，你可以定制自己的pytorch模型，**前提是这个模型必须是基于t.nn.Module开发，并实现了forward接口**. 将你实现好的模型文件放入federatedml/nn/model_zoo下, 在提交任务时通过接口指定该模块，homo-nn会自动搜寻并导入你实现的模型\n",
    "\n",
    "这里，为了完成MNIST分类任务，我们先本地编写一个带有卷积网络的NN模块:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "898046e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch as t\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class ImgNet(nn.Module):\n",
    "    def __init__(self, class_num=10):\n",
    "        super(ImgNet, self).__init__()\n",
    "        self.seq = t.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3),\n",
    "            nn.AvgPool2d(kernel_size=3)\n",
    "        )\n",
    "        \n",
    "        self.fc = t.nn.Sequential(\n",
    "            nn.Linear(48, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, class_num)\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.fc(x)\n",
    "        if self.training:\n",
    "            return x\n",
    "        else:\n",
    "            return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "081c727b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImgNet(\n",
       "  (seq): Sequential(\n",
       "    (0): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): AvgPool2d(kernel_size=3, stride=3, padding=0)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=48, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_model = ImgNet(10)\n",
    "img_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e799b0cc",
   "metadata": {},
   "source": [
    "将模型代码命名为image_net.py，可以直接把它放在federatedml/nn/model_zoo下\n",
    "\n",
    "或者使用jupyter notebook的快捷接口 直接将其保存到federatedml/nn/model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8207004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.component.homo_nn import save_to_fate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f972ba9f",
   "metadata": {},
   "source": [
    "## jupyter保存接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c5ce623",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%save_to_fate model image_net.py\n",
    "from torch import nn\n",
    "import torch as t\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class ImgNet(nn.Module):\n",
    "    def __init__(self, class_num=10):\n",
    "        super(ImgNet, self).__init__()\n",
    "        self.seq = t.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3),\n",
    "            nn.AvgPool2d(kernel_size=3)\n",
    "        )\n",
    "        \n",
    "        self.fc = t.nn.Sequential(\n",
    "            nn.Linear(48, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, class_num)\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.fc(x)\n",
    "        if self.training:\n",
    "            return x\n",
    "        else:\n",
    "            return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "749d50b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from torch import nn\r\n",
      "import torch as t\r\n",
      "from torch.nn import functional as F\r\n",
      "\r\n",
      "class ImgNet(nn.Module):\r\n",
      "    def __init__(self, class_num=10):\r\n",
      "        super(ImgNet, self).__init__()\r\n",
      "        self.seq = t.nn.Sequential(\r\n",
      "            nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5),\r\n",
      "            nn.MaxPool2d(kernel_size=3),\r\n",
      "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3),\r\n",
      "            nn.AvgPool2d(kernel_size=3)\r\n",
      "        )\r\n",
      "        \r\n",
      "        self.fc = t.nn.Sequential(\r\n",
      "            nn.Linear(48, 32),\r\n",
      "            nn.ReLU(),\r\n",
      "            nn.Linear(32, class_num)\r\n",
      "        )\r\n",
      "        self.softmax = nn.Softmax(dim=1)\r\n",
      "\r\n",
      "    def forward(self, x):\r\n",
      "        x = self.seq(x)\r\n",
      "        x = x.flatten(start_dim=1)\r\n",
      "        x = self.fc(x)\r\n",
      "        if self.training:\r\n",
      "            return x\r\n",
      "        else:\r\n",
      "            return self.softmax(x)\r\n"
     ]
    }
   ],
   "source": [
    "! cat ../fate/python/federatedml/nn/model_zoo/image_net.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0311ed01",
   "metadata": {},
   "source": [
    "## 进行本地测试\n",
    "\n",
    "我们可以先不急着提交任务，可以使用Trainer进行本地测试。上个教程提到，fate自带一个FedAVGTrainer\n",
    "\n",
    "我们可以使用我们的数据集，自定义的模型，和Trainer进行本地调试，测试是否能够跑通程序\n",
    "**本地测试的情况下，会跳过所有联邦流程，模型不会进行fed averaging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c53366f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federatedml.nn.homo.trainer.fedavg_trainer import FedAVGTrainer\n",
    "trainer = FedAVGTrainer(epochs=3, batch_size=256, shuffle=True, data_loader_worker=8) # 参数\n",
    "trainer.set_model(img_model) # 设置自定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "711ef7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.local_mode() # !! 请务必启用local_mode以跳过联邦流程 !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d65f9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch is 0\n",
      "epoch loss is 2.643130985082243\n",
      "epoch is 1\n",
      "epoch loss is 2.217886555367886\n",
      "epoch is 2\n",
      "epoch loss is 1.6585891059193565\n"
     ]
    }
   ],
   "source": [
    "optimizer = t.optim.Adam(img_model.parameters(), lr=0.01)\n",
    "loss = t.nn.CrossEntropyLoss()\n",
    "trainer.train(train_set=dataset,optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08ed729",
   "metadata": {},
   "source": [
    "可以跑通！那我们可以提交联邦任务了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413aefa9",
   "metadata": {},
   "source": [
    "## 提交使用自定义模型的Homo-NN任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1518af62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch' from '/home/cwj/standalone_fate_install_1.9.0_release/env/python/venv/lib/python3.8/site-packages/torch/__init__.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as t\n",
    "from torch import nn\n",
    "from pipeline import fate_torch_hook\n",
    "from pipeline.component import HomoNN\n",
    "from pipeline.backend.pipeline import PipeLine\n",
    "from pipeline.component import Reader, Evaluation, DataTransform\n",
    "from pipeline.interface import Data, Model\n",
    "\n",
    "fate_torch_hook(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d900c35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': 'experiment', 'table_name': 'mnist_host_1'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# 绑定地址到fate name&namespace\n",
    "fate_project_path = os.path.abspath('../')\n",
    "host_0 = 10000\n",
    "host_1 = 9999\n",
    "pipeline = PipeLine().set_initiator(role='host', party_id=host_0).set_roles(host=[host_0, host_1],\n",
    "                                                                            arbiter=[host_0])\n",
    "\n",
    "data_0 = {\"name\": \"mnist_host_0\", \"namespace\": \"experiment\"}\n",
    "data_1 = {\"name\": \"mnist_host_1\", \"namespace\": \"experiment\"}\n",
    "\n",
    "# 为方便，本示例中两个client使用同一份数据集\n",
    "data_path_0 = fate_project_path + '/examples/data/mnist'\n",
    "data_path_1 = fate_project_path + '/examples/data/mnist'\n",
    "pipeline.bind_table(name=data_0['name'], namespace=data_0['namespace'], path=data_path_0)\n",
    "pipeline.bind_table(name=data_1['name'], namespace=data_1['namespace'], path=data_path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3af79ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义reader\n",
    "reader_0 = Reader(name=\"reader_0\")\n",
    "reader_0.get_party_instance(role='host', party_id=host_0).component_param(table=data_0)\n",
    "reader_0.get_party_instance(role='host', party_id=host_1).component_param(table=data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de9917a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.component.homo_nn import DatasetParam, TrainerParam  # 数据集的接口\n",
    "from pipeline.component.nn.backend.torch.cust_model import CustModel  # 自定义模型的接口\n",
    "\n",
    "model = t.nn.Sequential(\n",
    "    t.nn.CustModel(module_name='image_net', class_name='ImgNet', class_num=10) \n",
    "    # module_name指定自定义模型的模块名，class_name指定你自定义的类, name之外的参数将会被传递到模型的__init__上，比如\n",
    "    # 此处的class_num\n",
    ")\n",
    "\n",
    "nn_component = HomoNN(name='nn_0',\n",
    "                      model=model, # 模型\n",
    "                      loss=t.nn.CrossEntropyLoss(),\n",
    "                      optimizer=t.optim.Adam(model.parameters(), lr=0.01),\n",
    "                      dataset=DatasetParam(dataset_name='image'),  # 使用image dataset\n",
    "                      trainer=TrainerParam(trainer_name='fedavg_trainer', epochs=3, batch_size=256, validation_freqs=1),\n",
    "                      torch_seed=100 # 全局随机种子\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62361f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pipeline.backend.pipeline.PipeLine at 0x7fca7baafd60>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 添加组件到pipeline，定义数据IO关系，提交即可\n",
    "pipeline.add_component(reader_0)\n",
    "pipeline.add_component(nn_component, data=Data(train_data=reader_0.output.data))\n",
    "pipeline.add_component(Evaluation(name='eval_0', eval_type='multi'), data=Data(data=nn_component.output.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fa46219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pipeline.backend.pipeline.PipeLine at 0x7fca808b0e50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.compile()\n",
    "pipeline.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5734f3",
   "metadata": {},
   "source": [
    "成功了！并且 我们可以用同样的方式，为任务加一个验证集，看看效果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3897be2",
   "metadata": {},
   "source": [
    "## 提交使用自定义模型的Homo-NN任务 + 验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ac41557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pipeline.backend.pipeline.PipeLine at 0x7fca7baafd00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as t\n",
    "from torch import nn\n",
    "from pipeline import fate_torch_hook\n",
    "from pipeline.component import HomoNN\n",
    "from pipeline.backend.pipeline import PipeLine\n",
    "from pipeline.component import Reader, Evaluation, DataTransform\n",
    "from pipeline.interface import Data, Model\n",
    "\n",
    "fate_torch_hook(t)\n",
    "\n",
    "import os\n",
    "# 绑定地址到fate name&namespace\n",
    "fate_project_path = os.path.abspath('../')\n",
    "host_0 = 10000\n",
    "host_1 = 9999\n",
    "pipeline = PipeLine().set_initiator(role='host', party_id=host_0).set_roles(host=[host_0, host_1],\n",
    "                                                                            arbiter=[host_0])\n",
    "\n",
    "validate_data = {\"name\": \"mnist_validate\", \"namespace\": \"experiment\"}\n",
    "\n",
    "# 为方便，本示例中两个client使用同一份数据集\n",
    "data_path_val = fate_project_path + '/examples/data/mnist_val'\n",
    "pipeline.bind_table(name=validate_data['name'], namespace=validate_data['namespace'], path=data_path_val)\n",
    "\n",
    "# 定义reader\n",
    "reader_0 = Reader(name=\"reader_0\")\n",
    "reader_0.get_party_instance(role='host', party_id=host_0).component_param(table=data_0)\n",
    "reader_0.get_party_instance(role='host', party_id=host_1).component_param(table=data_1)\n",
    "# validate data\n",
    "reader_1 = Reader(name=\"reader_1\")\n",
    "reader_1.get_party_instance(role='host', party_id=host_0).component_param(table=validate_data)\n",
    "reader_1.get_party_instance(role='host', party_id=host_1).component_param(table=validate_data)\n",
    "\n",
    "from pipeline.component.homo_nn import DatasetParam, TrainerParam  # 数据集的接口\n",
    "from pipeline.component.nn.backend.torch.cust_model import CustModel  # 自定义模型的接口\n",
    "\n",
    "model = t.nn.Sequential(\n",
    "     t.nn.CustModel(module_name='image_net', class_name='ImgNet', class_num=10) \n",
    "    # module_name指定自定义模型的模块名，class_name指定你自定义的类, name之外的参数将会被传递到模型的__init__上，比如\n",
    "    # 此处的class_num\n",
    ")\n",
    "\n",
    "nn_component = HomoNN(name='nn_0',\n",
    "                      model=model, # 模型\n",
    "                      loss=t.nn.CrossEntropyLoss(),\n",
    "                      optimizer=t.optim.Adam(model.parameters(), lr=0.01),\n",
    "                      dataset=DatasetParam(dataset_name='image'),  # 使用image dataset\n",
    "                      trainer=TrainerParam(trainer_name='fedavg_trainer', epochs=3, batch_size=256, validation_freqs=1),\n",
    "                      torch_seed=100 # 全局随机种子\n",
    "                      )\n",
    "\n",
    "# 添加组件到pipeline，定义数据IO关系，提交即可\n",
    "pipeline.add_component(reader_0)\n",
    "pipeline.add_component(reader_1)\n",
    "pipeline.add_component(nn_component, data=Data(train_data=reader_0.output.data, validate_data=reader_1.output.data))\n",
    "pipeline.add_component(Evaluation(name='eval_0', eval_type='multi'), data=Data(data=nn_component.output.data))\n",
    "pipeline.compile()\n",
    "pipeline.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
