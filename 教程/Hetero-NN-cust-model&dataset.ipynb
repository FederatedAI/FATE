{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d19012c",
   "metadata": {},
   "source": [
    "# Hetero NN 自定义: 自定义Top/Bottom Model 和 自定义数据集\n",
    "\n",
    "在该版本中 整个nn的架构有很大的调整，nn模块开发了dataset与model_zoo模块，旨在提供数据集和模型的自定义功能，\n",
    "\n",
    "Hetero-NN的模型与数据集的自定义，与Homo-NN十分相似，建议也阅读下Homo-NN自定义的教程，但是Hetero-NN在定义数据集时，对接口实现会多一些要求\n",
    "\n",
    "在这个教程中， 我们将会介绍hetero-nn下使用dataset,model_zoo的方式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a11164c",
   "metadata": {},
   "source": [
    "# 使用FATE自带数据集&数据集的自定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09efa963",
   "metadata": {},
   "source": [
    "Fate中nn.dataset下提供了一个Dataset基类，基于Pytorch Dataset开发。基于Dataset实现的数据集类，将其更新到nn.dataset模块中，FATE在运行时便可根据参数导入您自定义的数据集，进行训练。\n",
    "\n",
    "在纵向联邦学习Hetero-NN中，对Dataset的开发使用，相比于Homo-NN会有更多要求：\n",
    "- 考虑到guest与host方的id对齐问题，Dataset需要提供正确的样本id(sample id)，并确保guest/host方的数据集样本数量相同，sample id集合相同，这样才能保证您算法运行的正确性\n",
    "- 设计host方使用的数据集时，\\_\\_getitem\\_\\_方法仅仅返回数据，不返回label，否则算法流程会报错\n",
    "- 当使用自定义数据集时，Hetero-NN便无法使用为FATE Table设计的交集算法，你需要另外上传sample id进行样本对齐。\n",
    "\n",
    "因此，在继承Dataset模块开发时，除了\\_\\_getitem\\_\\_， \\_\\_len\\_\\_，load，你还需额外实现两个要求: 1. 实现 get_classes 2. 初始化或者load时调用set_sample_ids方法设置样本id\n",
    "\n",
    "FATE自带的图像，文本数据集模块: image和nlp_tokenizer都实现了不返回label的参数return_label，并且会自动解析设置sample_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7521bfa9",
   "metadata": {},
   "source": [
    "## 样例：实现一个简单的图像数据集，用于Hetero-NN任务\n",
    "\n",
    "为了更好理解Hetero-NN下Dataset定制的一些要求，这里我们实现一个简单的图片数据集，读取MNIST图像，完成一个Hetero-NN场景下的图片分类任务\n",
    "这里为了方便，我们用save_to_fate的jupyter接口，把代码更新到federatedml.nn.dataset下，名为mnist_dataset.py，当然你可以手动拷贝代码\n",
    "文件到目录下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2446d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.component.homo_nn import save_to_fate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f35b7c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%save_to_fate dataset mnist_dataset.py\n",
    "import numpy as np\n",
    "from federatedml.nn.dataset.base import Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, return_label=True):  # guest方有标签，return label = True, host方无标签，return label = False\n",
    "        super(MNISTDataset, self).__init__() # 记得这个\n",
    "        self.return_label = return_label\n",
    "        self.image_folder = None\n",
    "        \n",
    "    def load(self, path):  # 实现label 接口，从path读取图像， 设置sample ids\n",
    "        \n",
    "        # 读取\n",
    "        self.image_folder = ImageFolder(root=path, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "        # 用image的名字作为id\n",
    "        ids = []\n",
    "        for image_name in self.image_folder.imgs:\n",
    "            ids.append(image_name[0].split('/')[-1].replace('.jpg', ''))\n",
    "        self.set_sample_ids(ids)\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def get_classes(self, ): # get classes接口，返回class种类， guest方需要用到\n",
    "        return np.unique(self.image_folder.targets).tolist()\n",
    "    \n",
    "    def __len__(self,):  # len接口\n",
    "        return len(self.image_folder)\n",
    "    \n",
    "    def __getitem__(self, idx): # get item 接口, 注意return label\n",
    "        ret = self.image_folder[idx]\n",
    "        img = ret[0][0].flatten() # 转换为一个flatten tensor 784维度\n",
    "        if self.return_label:\n",
    "            return img, ret[1] # img & label\n",
    "        else:\n",
    "            return img # no label, for host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5890ae8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  1  2  3  4  5  6  7\t8  9\n",
      "1309\n",
      "torch.Size([784]) 0\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "['img_1', 'img_1029', 'img_1046', 'img_1047', 'img_1076', 'img_108', 'img_1091', 'img_1093', 'img_1096', 'img_110']\n"
     ]
    }
   ],
   "source": [
    "# 测试一下能不能用 guest\n",
    "! ls ../examples/data/mnist_guest/  # 十个类\n",
    "ds = MNISTDataset().load('../examples/data/mnist_guest/')\n",
    "print(len(ds))\n",
    "print(ds[0][0].shape, ds[0][1]) # 有label\n",
    "print(ds.get_classes())\n",
    "print(ds.get_sample_ids()[0: 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7376e75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not_labeled\n",
      "1309\n",
      "torch.Size([784])\n"
     ]
    }
   ],
   "source": [
    "# 测试一下能不能用 host\n",
    "! ls ../examples/data/mnist_host/  # 所有图片放到一个文件夹里 无标签\n",
    "ds = MNISTDataset(return_label=False).load('../examples/data/mnist_host/')\n",
    "print(len(ds))\n",
    "print(ds[0].shape) # 无label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee066f26",
   "metadata": {},
   "source": [
    "Good! 可以用了, 那我们现在用这个开发的数据集跑一个Hetero-NN模型，双方用id对齐的两个数据集mnist_guest & mnist_host进行一次横向联邦训练\n",
    "\n",
    "在使用时，我们不再遵循常规FATE组件的用法，而是直接绑定数据集地址到一个FATE的name&namespace 通过reader传递给Hetero-NN组件，Hetero-NN通过你设置\n",
    "的DatasetParam调用你自定义的数据集，从path读取数据，进行训练:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce4aa4d",
   "metadata": {},
   "source": [
    "### pipeline 初始化 绑定path到name&namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "19b44a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': 'experiment', 'table_name': 'mnist_host'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch as t\n",
    "from torch import nn\n",
    "from pipeline import fate_torch_hook\n",
    "from pipeline.component import HeteroNN\n",
    "from pipeline.component.hetero_nn import DatasetParam\n",
    "from pipeline.component.nn.backend.torch.cust_model import CustModel\n",
    "from pipeline.backend.pipeline import PipeLine\n",
    "from pipeline.component import Reader, Evaluation, DataTransform\n",
    "from pipeline.interface import Data, Model\n",
    "from pipeline.component.homo_nn import save_to_fate\n",
    "\n",
    "fate_torch_hook(t)\n",
    "\n",
    "# 绑定地址到fate name&namespace\n",
    "fate_project_path = os.path.abspath('../')\n",
    "guest = 10000\n",
    "host = 9999\n",
    "\n",
    "pipeline_img = PipeLine().set_initiator(role='guest', party_id=guest).set_roles(guest=guest, host=host)\n",
    "\n",
    "guest_data = {\"name\": \"mnist_guest\", \"namespace\": \"experiment\"}\n",
    "host_data = {\"name\": \"mnist_host\", \"namespace\": \"experiment\"}\n",
    "\n",
    "guest_data_path = fate_project_path + '/examples/data/mnist_guest/'\n",
    "host_data_path = fate_project_path + '/examples/data/mnist_host/'\n",
    "pipeline_img.bind_table(name='mnist_guest', namespace='experiment', path=guest_data_path)\n",
    "pipeline_img.bind_table(name='mnist_host', namespace='experiment', path=host_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9aeccf",
   "metadata": {},
   "source": [
    "### 定义HeteroNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "576f2e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "guest_data = {\"name\": \"mnist_guest\", \"namespace\": \"cwj\"}\n",
    "host_data = {\"name\": \"mnist_host\", \"namespace\": \"cwj\"}\n",
    "reader_0 = Reader(name=\"reader_0\")\n",
    "reader_0.get_party_instance(role='guest', party_id=guest).component_param(table=guest_data)\n",
    "reader_0.get_party_instance(role='host', party_id=host).component_param(table=host_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d3b8fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hetero_nn_0 = HeteroNN(name=\"hetero_nn_0\", epochs=5,\n",
    "                       interactive_layer_lr=0.01, batch_size=128, validation_freqs=None, task_type='classification', seed=114514)\n",
    "\n",
    "# 设置不同party的模型结构与数据集\n",
    "guest_nn_0 = hetero_nn_0.get_party_instance(role='guest', party_id=guest)\n",
    "host_nn_0 = hetero_nn_0.get_party_instance(role='host', party_id=host)\n",
    "\n",
    "# 定义模型\n",
    "# 图像特征784 单层模型\n",
    "guest_bottom = t.nn.Sequential(\n",
    "    nn.Linear(784, 32),\n",
    "    nn.ReLU()\n",
    ")\n",
    "# 图像特征784 单层模型\n",
    "host_bottom = t.nn.Sequential(\n",
    "    nn.Linear(784,32),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "# Top Model 是个分类器\n",
    "guest_top = t.nn.Sequential(\n",
    "    nn.Linear(16, 10), # 10类\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "\n",
    "# fate_torch_hook后，nn模块可以使用InteractiveLayer\n",
    "interactive_layer = t.nn.InteractiveLayer(out_dim=16, guest_dim=32, host_dim=32)\n",
    "\n",
    "# 添加模型\n",
    "guest_nn_0.add_top_model(guest_top)\n",
    "guest_nn_0.add_bottom_model(guest_bottom)\n",
    "host_nn_0.add_bottom_model(host_bottom)\n",
    "\n",
    "# 优化器 loss函数\n",
    "optimizer = t.optim.Adam(lr=0.01) # 注意！fate_torch_hook后，优化器可以不用parameter参数\n",
    "loss = t.nn.CrossEntropyLoss()\n",
    "\n",
    "# 设置数据集，这里使用DatasetParam， dataset_name为模块名，其余的参数会被传递到数据集的__init__接口上\n",
    "# host 方不需要return label, return_label = False\n",
    "guest_nn_0.add_dataset(DatasetParam(dataset_name='mnist_dataset', return_label=True))\n",
    "host_nn_0.add_dataset(DatasetParam(dataset_name='mnist_dataset', return_label=False))\n",
    "\n",
    "hetero_nn_0.set_interactve_layer(interactive_layer)\n",
    "hetero_nn_0.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b4e4a004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pipeline.backend.pipeline.PipeLine at 0x7f5eda94b580>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_img.add_component(reader_0)\n",
    "pipeline_img.add_component(hetero_nn_0, data=Data(train_data=reader_0.output.data))\n",
    "pipeline_img.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3913af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_img.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "88a6dbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>predict_result</th>\n",
       "      <th>predict_score</th>\n",
       "      <th>predict_detail</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9976044297218323</td>\n",
       "      <td>{'0': 0.9976044297218323, '1': 1.8047569028567...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9073200821876526</td>\n",
       "      <td>{'0': 0.0010162688558921218, '1': 0.0317202284...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9976639747619629</td>\n",
       "      <td>{'0': 0.9976639747619629, '1': 5.3269786803866...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6787770986557007</td>\n",
       "      <td>{'0': 0.15763959288597107, '1': 3.596510214265...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.99482262134552</td>\n",
       "      <td>{'0': 6.393105422830558e-07, '1': 1.4373620160...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>img_32537</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9985225796699524</td>\n",
       "      <td>{'0': 1.5916774032120884e-07, '1': 0.998522579...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>img_32558</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9956049919128418</td>\n",
       "      <td>{'0': 3.0502631034323713e-06, '1': 0.995604991...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>img_32563</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9994334578514099</td>\n",
       "      <td>{'0': 4.608472181644174e-08, '1': 0.9994334578...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>img_32565</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.36305826902389526</td>\n",
       "      <td>{'0': 0.0028015582356601954, '1': 0.0293765980...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>img_32573</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9985238909721375</td>\n",
       "      <td>{'0': 1.1269445110428933e-07, '1': 0.998523890...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id label  ...                                     predict_detail   type\n",
       "0         img_1     0  ...  {'0': 0.9976044297218323, '1': 1.8047569028567...  train\n",
       "1         img_3     4  ...  {'0': 0.0010162688558921218, '1': 0.0317202284...  train\n",
       "2         img_4     0  ...  {'0': 0.9976639747619629, '1': 5.3269786803866...  train\n",
       "3         img_5     0  ...  {'0': 0.15763959288597107, '1': 3.596510214265...  train\n",
       "4         img_6     7  ...  {'0': 6.393105422830558e-07, '1': 1.4373620160...  train\n",
       "...         ...   ...  ...                                                ...    ...\n",
       "1304  img_32537     1  ...  {'0': 1.5916774032120884e-07, '1': 0.998522579...  train\n",
       "1305  img_32558     1  ...  {'0': 3.0502631034323713e-06, '1': 0.995604991...  train\n",
       "1306  img_32563     1  ...  {'0': 4.608472181644174e-08, '1': 0.9994334578...  train\n",
       "1307  img_32565     1  ...  {'0': 0.0028015582356601954, '1': 0.0293765980...  train\n",
       "1308  img_32573     1  ...  {'0': 1.1269445110428933e-07, '1': 0.998523890...  train\n",
       "\n",
       "[1309 rows x 6 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_img.get_component('hetero_nn_0').get_output_data()  # get result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3608739",
   "metadata": {},
   "source": [
    "# 模型的自定义\n",
    "\n",
    "Hetero-NN与Homo-NN 共用model_zoo模块，因此自定义模型的方法与Homo-NN没任何区别，在使用时，请注意Bottom,interactive, Top模型之间的\n",
    "输入输出是否能对上，以及Top模型的输出与label的shape，和数据类型是否能正确的算出loss\n",
    "\n",
    "在本节，我们以flicker数据集为例，guest方有图像，以及2分类标签；而host方，有对图像的文本描述，因此，我们guest方使用fate自带的图像数据集和处理图像的模型，\n",
    "而host使用一个lstm模型，和fate自带的nlp数据集\n",
    "\n",
    "这里自定义了guest bottom/top以及host bottom的模型，interactive layer不支持自定义，我们使用save_to_fate进行快捷保存，或者你可以手动把他们都放到nn.model_zoo下"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdde3a2",
   "metadata": {},
   "source": [
    "### Guest Model 自定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "98e9a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%save_to_fate model guest_bottom_image.py\n",
    "from torch import nn\n",
    "import torch as t\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class ImgBottomNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImgBottomNet, self).__init__()\n",
    "        self.seq = t.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Conv2d(in_channels=6, out_channels=6, kernel_size=3),\n",
    "            nn.AvgPool2d(kernel_size=5)\n",
    "        )\n",
    "        \n",
    "        self.fc = t.nn.Sequential(\n",
    "            nn.Linear(1176, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 8)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f2a81854",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%save_to_fate model guest_top_image.py\n",
    "\n",
    "from torch import nn\n",
    "import torch as t\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class ImgTopNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImgTopNet, self).__init__()\n",
    "        \n",
    "        self.fc = t.nn.Sequential(\n",
    "            nn.Linear(4, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abea2f8e",
   "metadata": {},
   "source": [
    "### Host Model 自定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "84d92fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%save_to_fate model host_bottom_lstm.py\n",
    "from torch import nn\n",
    "import torch as t\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class LSTMBottom(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super(LSTMBottom, self).__init__()\n",
    "        self.word_embed = nn.Embedding(num_embeddings=vocab_size, embedding_dim=16, padding_idx=0)\n",
    "        self.lstm = t.nn.Sequential(\n",
    "            nn.LSTM(input_size=16, hidden_size=16, num_layers=2, batch_first=True)\n",
    "        )\n",
    "        self.act = nn.ReLU()\n",
    "        self.linear = nn.Linear(16, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = self.word_embed(x)\n",
    "        lstm_fw, _ = self.lstm(embeddings)\n",
    "        \n",
    "        return self.act(self.linear(lstm_fw.sum(dim=1)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67515a5",
   "metadata": {},
   "source": [
    "### 本地测试数据集，模型\n",
    "\n",
    "这里我们测试一下我们的数据，还有定义的模型是否能正常工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e6bca16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federatedml.nn.dataset.image import ImageDataset\n",
    "from federatedml.nn.dataset.nlp_tokenizer import TokenizerDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f3495837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flicke图像数据集\n",
    "img_ds = ImageDataset(center_crop=True, center_crop_shape=(224, 224), return_label=True) # return label = True\n",
    "img_ds.load('../examples/data/flicker_toy_data/flicker/images/')\n",
    "# 文本数据集\n",
    "txt_ds = TokenizerDataset(return_label=False) # host端无label\n",
    "txt_ds.load('../examples/data/flicker_toy_data/text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7542d6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n",
      "(tensor([[[0.5059, 0.5176, 0.5137,  ..., 0.4941, 0.5020, 0.5059],\n",
      "         [0.4980, 0.5020, 0.4980,  ..., 0.4824, 0.5020, 0.5059],\n",
      "         [0.5059, 0.4863, 0.4902,  ..., 0.4980, 0.4980, 0.5137],\n",
      "         ...,\n",
      "         [0.7843, 0.7922, 0.7529,  ..., 0.1412, 0.2078, 0.2196],\n",
      "         [0.9922, 0.9922, 0.9647,  ..., 0.1176, 0.0941, 0.1333],\n",
      "         [0.9961, 0.9922, 1.0000,  ..., 0.1647, 0.1294, 0.1373]],\n",
      "\n",
      "        [[0.5765, 0.5882, 0.5843,  ..., 0.5490, 0.5569, 0.5608],\n",
      "         [0.5686, 0.5804, 0.5765,  ..., 0.5490, 0.5529, 0.5529],\n",
      "         [0.5608, 0.5569, 0.5647,  ..., 0.5569, 0.5490, 0.5529],\n",
      "         ...,\n",
      "         [0.7961, 0.8039, 0.7490,  ..., 0.1373, 0.1882, 0.2000],\n",
      "         [0.9961, 0.9961, 0.9608,  ..., 0.1137, 0.1137, 0.1529],\n",
      "         [0.9922, 0.9922, 1.0000,  ..., 0.1608, 0.1059, 0.1216]],\n",
      "\n",
      "        [[0.6235, 0.6353, 0.6314,  ..., 0.5922, 0.6000, 0.6118],\n",
      "         [0.6078, 0.6235, 0.6196,  ..., 0.5804, 0.5882, 0.6000],\n",
      "         [0.6039, 0.6118, 0.6196,  ..., 0.5843, 0.5843, 0.6000],\n",
      "         ...,\n",
      "         [0.5882, 0.5961, 0.5686,  ..., 0.1216, 0.1765, 0.1882],\n",
      "         [0.7294, 0.7373, 0.7373,  ..., 0.0980, 0.0980, 0.1294],\n",
      "         [0.8745, 0.8431, 0.8627,  ..., 0.1451, 0.1059, 0.1176]]]), tensor(0))\n",
      "[0, 1]\n",
      "['1022454428_b6b660a67b', '103195344_5d2dc613a3', '1055753357_4fa3d8d693', '1124448967_2221af8dc5', '1131804997_177c3c0640', '1138784872_69ade3f2ab', '1142847777_2a0c1c2551', '1143373711_2e90b7b799', '1143882946_1898d2eeb9', '1144288288_e5c9558b6a']\n"
     ]
    }
   ],
   "source": [
    "print(len(img_ds))\n",
    "print(img_ds[0])\n",
    "print(img_ds.get_classes())\n",
    "print(img_ds.get_sample_ids()[0: 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6fae43a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n",
      "tensor([  101,  1037,  2158,  1998,  2450,  2729,  2005,  2019, 10527,  2247,\n",
      "         1996,  2217,  1997,  1037,  2303,  1997,  2300,  1012,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0])\n",
      "30522\n"
     ]
    }
   ],
   "source": [
    "print(len(txt_ds))\n",
    "print(txt_ds[0]) # word idx\n",
    "print(txt_ds.get_vocab_size()) # 词汇表大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c857db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试下模型是否可用\n",
    "img_bottom = ImgBottomNet()\n",
    "lstm_bottom = LSTMBottom(vocab_size=txt_ds.get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c4fd9b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2519, 1.6196],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1977, 1.0931]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_bottom(t.vstack([txt_ds[0], txt_ds[1]]))  # forward是否OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9add8cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0045, -0.0910,  0.1303,  0.0460,  0.0381, -0.0751,  0.0361,  0.1149],\n",
       "        [ 0.0267, -0.1280,  0.1166,  0.0720,  0.0644, -0.0472,  0.0101,  0.0964]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_bottom(t.vstack([img_ds[0][0].unsqueeze(dim=0), img_ds[1][0].unsqueeze(dim=0)])) # 可用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9950c6bd",
   "metadata": {},
   "source": [
    "### 提交pipeline \n",
    "本地初步测试OK，我们提交一个Pipeline任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d4a51493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': 'experiment', 'table_name': 'flicker_host'}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch as t\n",
    "from torch import nn\n",
    "from pipeline import fate_torch_hook\n",
    "from pipeline.component import HeteroNN\n",
    "from pipeline.component.hetero_nn import DatasetParam\n",
    "from pipeline.component.nn.backend.torch.cust_model import CustModel\n",
    "from pipeline.backend.pipeline import PipeLine\n",
    "from pipeline.component import Reader, Evaluation, DataTransform\n",
    "from pipeline.interface import Data, Model\n",
    "from pipeline.component.homo_nn import save_to_fate\n",
    "\n",
    "fate_torch_hook(t)\n",
    "\n",
    "# 绑定地址到fate name&namespace\n",
    "fate_project_path = os.path.abspath('../')\n",
    "guest = 10000\n",
    "host = 9999\n",
    "\n",
    "pipeline_mix = PipeLine().set_initiator(role='guest', party_id=guest).set_roles(guest=guest, host=host)\n",
    "\n",
    "guest_data = {\"name\": \"flicker_guest\", \"namespace\": \"experiment\"}\n",
    "host_data = {\"name\": \"flicker_host\", \"namespace\": \"experiment\"}\n",
    "\n",
    "guest_data_path = fate_project_path + '/examples/data/flicker_toy_data/flicker/images'\n",
    "host_data_path = fate_project_path + '/examples/data/flicker_toy_data/text.csv'\n",
    "\n",
    "pipeline_mix.bind_table(name='flicker_guest', namespace='experiment', path=guest_data_path)\n",
    "pipeline_mix.bind_table(name='flicker_host', namespace='experiment', path=host_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "50efe200",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_0 = Reader(name=\"reader_0\")\n",
    "reader_0.get_party_instance(role='guest', party_id=guest).component_param(table=guest_data)\n",
    "reader_0.get_party_instance(role='host', party_id=host).component_param(table=host_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4475a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "hetero_nn_0 = HeteroNN(name=\"hetero_nn_0\", epochs=5,\n",
    "                       interactive_layer_lr=0.001, batch_size=64, validation_freqs=1, task_type='classification')\n",
    "guest_nn_0 = hetero_nn_0.get_party_instance(role='guest', party_id=guest)\n",
    "host_nn_0 = hetero_nn_0.get_party_instance(role='host', party_id=host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a2a591e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom model\n",
    "guest_bottom = nn.CustModel(name='guest_bottom_image')\n",
    "\n",
    "# 放在sequential里也行\n",
    "guest_top = t.nn.Sequential(\n",
    "    nn.CustModel(name='guest_top_image')\n",
    ")\n",
    "# bottom model\n",
    "host_bottom = nn.CustModel(name='host_bottom_lstm', vocab_size=txt_ds.get_vocab_size())\n",
    "\n",
    "interactive_layer = t.nn.InteractiveLayer(out_dim=4, guest_dim=8, host_dim=8, host_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b8799751",
   "metadata": {},
   "outputs": [],
   "source": [
    "guest_nn_0.add_top_model(guest_top)\n",
    "guest_nn_0.add_bottom_model(guest_bottom)\n",
    "host_nn_0.add_bottom_model(host_bottom)\n",
    "optimizer = t.optim.Adam(lr=0.001)\n",
    "loss = t.nn.BCELoss()\n",
    "\n",
    "hetero_nn_0.set_interactve_layer(interactive_layer)\n",
    "hetero_nn_0.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ea5dae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加dataset\n",
    "guest_nn_0.add_dataset(DatasetParam(dataset_name='image', return_label=True, center_crop=True, center_crop_shape=(224, 224), label_dtype='float'))\n",
    "host_nn_0.add_dataset(DatasetParam(dataset_name='nlp_tokenizer', return_label=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "aa06e1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pipeline.backend.pipeline.PipeLine at 0x7f5ece42a310>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_mix.add_component(reader_0)\n",
    "pipeline_mix.add_component(hetero_nn_0, data=Data(train_data=reader_0.output.data))\n",
    "pipeline_mix.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc60285",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_mix.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583f1ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
