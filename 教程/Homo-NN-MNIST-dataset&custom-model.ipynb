{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a982d9b",
   "metadata": {},
   "source": [
    "# Homo NN MNIST图像分类: 介绍数据集与模型自定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b31519",
   "metadata": {},
   "source": [
    "在该版本中 整个nn的架构有很大的调整，nn模块开发了dataset与model_zoo模块，旨在提供数据集和模型的自定义功能，在这个教程中， 我们将会介绍nn的Dataset机制，以及介绍如何进行模型自定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e255e886",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57e6ec",
   "metadata": {},
   "source": [
    "在 FATE-1.10中，FATE基于pytorch的Dataset类开发一个新的Dataset基类，用户可以基于这个类，实现\\_\\_getitem\\_\\_, \\_\\_len\\_\\_, load接口，\n",
    "load接口接收一个地址，可以从本地读取数据。当提交任务时，可以通过reader组件输入数据地址，HomoNN会使用用户指定的Dataset，使用load接口读取数据，使用数据集进行训练\n",
    "\n",
    "在FATE-1.10中，提供了table, nlp_tokenizer, image三种数据集，以满足基本的使用需要，但是用户可以随意自定义自己的dataset，dataset的自定义将会在下一教程介绍\n",
    "\n",
    "本次教程，我们介绍image数据集，它基于pytorch的ImageFolder类开发"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c6b20",
   "metadata": {},
   "source": [
    "### ImageDataset\n",
    "此处 我们用ImageDataset来加载MNIST数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0000f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federatedml.nn.dataset.image import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28fcd702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  1  2  3  4  5  6  7\t8  9\r\n"
     ]
    }
   ],
   "source": [
    "# 查看mnist数据集文件夹结构，一共10个文件夹，每个文件夹下放有各个类图像，使用方式与ImageFolder一致\n",
    "! ls ../examples/data/mnist_folder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf4d85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset()\n",
    "dataset.load('../examples/data/mnist/') # 读取mnist数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a558125e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fdd37eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0275, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0118, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.0275, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0118, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.0275, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0118, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]),\n",
       " tensor(3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[400] # 查看图像 与ImageFolder使用方式一致"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a3a2d",
   "metadata": {},
   "source": [
    "## 自定义模型\n",
    "\n",
    "在 FATE-1.10中，FATE可以通过pipeline提交pytorch Sequential模型.然而，Sequential结合pytorch自带的layer, 还是无法表示更为复杂的模型\n",
    "\n",
    "因此，FATE-1.10中加入了model_zoo模块，位于federatedml.nn.model_zoo下。现在，你可以定制自己的pytorch模型，**前提是这个模型必须是基于t.nn.Module开发，并实现了forward接口**. 将你实现好的模型文件放入federatedml/nn/model_zoo下, 在提交任务时通过接口指定该模块，homo-nn会自动搜寻并导入你实现的模型\n",
    "\n",
    "这里，为了完成MNIST分类任务，我们先本地编写一个带有卷积网络的NN模块:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "898046e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch as t\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class ImgNet(nn.Module):\n",
    "    def __init__(self, class_num=10):\n",
    "        super(ImgNet, self).__init__()\n",
    "        self.seq = t.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3),\n",
    "            nn.AvgPool2d(kernel_size=3)\n",
    "        )\n",
    "        \n",
    "        self.fc = t.nn.Sequential(\n",
    "            nn.Linear(48, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, class_num)\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.fc(x)\n",
    "        if self.training:\n",
    "            return x\n",
    "        else:\n",
    "            return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "081c727b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImgNet(\n",
       "  (seq): Sequential(\n",
       "    (0): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): AvgPool2d(kernel_size=3, stride=3, padding=0)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=48, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_model = ImgNet(10)\n",
    "img_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e799b0cc",
   "metadata": {},
   "source": [
    "将模型代码命名为image_net.py，可以直接把它放在federatedml/nn/model_zoo下\n",
    "\n",
    "或者使用jupyter notebook的快捷接口 直接将其保存到federatedml/nn/model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8207004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.component.homo_nn import save_to_fate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f972ba9f",
   "metadata": {},
   "source": [
    "## jupyter保存接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c5ce623",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%save_to_fate model image_net.py\n",
    "from torch import nn\n",
    "import torch as t\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class ImgNet(nn.Module):\n",
    "    def __init__(self, class_num=10):\n",
    "        super(ImgNet, self).__init__()\n",
    "        self.seq = t.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3),\n",
    "            nn.AvgPool2d(kernel_size=3)\n",
    "        )\n",
    "        \n",
    "        self.fc = t.nn.Sequential(\n",
    "            nn.Linear(48, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, class_num)\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.fc(x)\n",
    "        if self.training:\n",
    "            return x\n",
    "        else:\n",
    "            return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "749d50b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from torch import nn\r\n",
      "import torch as t\r\n",
      "from torch.nn import functional as F\r\n",
      "\r\n",
      "class ImgNet(nn.Module):\r\n",
      "    def __init__(self, class_num=10):\r\n",
      "        super(ImgNet, self).__init__()\r\n",
      "        self.seq = t.nn.Sequential(\r\n",
      "            nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5),\r\n",
      "            nn.MaxPool2d(kernel_size=3),\r\n",
      "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3),\r\n",
      "            nn.AvgPool2d(kernel_size=3)\r\n",
      "        )\r\n",
      "        \r\n",
      "        self.fc = t.nn.Sequential(\r\n",
      "            nn.Linear(48, 32),\r\n",
      "            nn.ReLU(),\r\n",
      "            nn.Linear(32, class_num)\r\n",
      "        )\r\n",
      "        self.softmax = nn.Softmax(dim=1)\r\n",
      "\r\n",
      "    def forward(self, x):\r\n",
      "        x = self.seq(x)\r\n",
      "        x = x.flatten(start_dim=1)\r\n",
      "        x = self.fc(x)\r\n",
      "        if self.training:\r\n",
      "            return x\r\n",
      "        else:\r\n",
      "            return self.softmax(x)\r\n"
     ]
    }
   ],
   "source": [
    "! cat ../fate/python/federatedml/nn/model_zoo/image_net.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0311ed01",
   "metadata": {},
   "source": [
    "## 进行本地测试\n",
    "\n",
    "我们可以先不急着提交任务，可以使用Trainer进行本地测试。上个教程提到，fate自带一个FedAVGTrainer\n",
    "\n",
    "我们可以使用我们的数据集，自定义的模型，和Trainer进行本地调试，测试是否能够跑通程序\n",
    "**本地测试的情况下，会跳过所有联邦流程，模型不会进行fed averaging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c53366f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federatedml.nn.homo.trainer.fedavg_trainer import FedAVGTrainer\n",
    "trainer = FedAVGTrainer(epochs=3, batch_size=256, shuffle=True, data_loader_worker=8) # 参数\n",
    "trainer.set_model(img_model) # 设置自定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "711ef7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.local_mode() # !! 请务必启用local_mode以跳过联邦流程 !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d65f9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch is 0\n",
      "epoch loss is 2.280080816780364\n",
      "epoch is 1\n",
      "epoch loss is 2.0551508919167283\n",
      "epoch is 2\n",
      "epoch loss is 1.5070739016449115\n"
     ]
    }
   ],
   "source": [
    "optimizer = t.optim.Adam(img_model.parameters(), lr=0.01)\n",
    "loss = t.nn.CrossEntropyLoss()\n",
    "trainer.train(train_set=dataset,optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08ed729",
   "metadata": {},
   "source": [
    "可以跑通！那我们可以提交联邦任务了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413aefa9",
   "metadata": {},
   "source": [
    "## 提交使用自定义模型的Homo-NN任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1518af62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch' from '/home/cwj/standalone_fate_install_1.9.0_release/env/python/venv/lib/python3.8/site-packages/torch/__init__.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as t\n",
    "from torch import nn\n",
    "from pipeline import fate_torch_hook\n",
    "from pipeline.component import HomoNN\n",
    "from pipeline.backend.pipeline import PipeLine\n",
    "from pipeline.component import Reader, Evaluation, DataTransform\n",
    "from pipeline.interface import Data, Model\n",
    "\n",
    "fate_torch_hook(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d900c35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': 'experiment', 'table_name': 'mnist_host_1'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# 绑定地址到fate name&namespace\n",
    "fate_project_path = os.path.abspath('../')\n",
    "host_0 = 10000\n",
    "host_1 = 9999\n",
    "pipeline = PipeLine().set_initiator(role='host', party_id=host_0).set_roles(host=[host_0, host_1],\n",
    "                                                                            arbiter=[host_0])\n",
    "\n",
    "data_0 = {\"name\": \"mnist_host_0\", \"namespace\": \"experiment\"}\n",
    "data_1 = {\"name\": \"mnist_host_1\", \"namespace\": \"experiment\"}\n",
    "\n",
    "# 为方便，本示例中两个client使用同一份数据集\n",
    "data_path_0 = fate_project_path + '/examples/data/mnist'\n",
    "data_path_1 = fate_project_path + '/examples/data/mnist'\n",
    "pipeline.bind_table(name=data_0['name'], namespace=data_0['namespace'], path=data_path_0)\n",
    "pipeline.bind_table(name=data_1['name'], namespace=data_1['namespace'], path=data_path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3af79ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义reader\n",
    "reader_0 = Reader(name=\"reader_0\")\n",
    "reader_0.get_party_instance(role='host', party_id=host_0).component_param(table=data_0)\n",
    "reader_0.get_party_instance(role='host', party_id=host_1).component_param(table=data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de9917a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.component.homo_nn import DatasetParam, TrainerParam  # 数据集的接口\n",
    "from pipeline.component.nn.backend.torch.cust_model import CustModel  # 自定义模型的接口\n",
    "\n",
    "model = t.nn.Sequential(\n",
    "    t.nn.CustModel(name='image_net', class_num=10) # name指定自定义模型的模块名，name之外的参数将会被传递到模型的__init__上，比如\n",
    "                                                    # 此处的class_num\n",
    ")\n",
    "\n",
    "nn_component = HomoNN(name='nn_0',\n",
    "                      model=model, # 模型\n",
    "                      loss=t.nn.CrossEntropyLoss(),\n",
    "                      optimizer=t.optim.Adam(model.parameters(), lr=0.01),\n",
    "                      dataset=DatasetParam(dataset_name='image'),  # 使用image dataset\n",
    "                      trainer=TrainerParam(trainer_name='fedavg_trainer', epochs=3, batch_size=256, validation_freqs=1),\n",
    "                      torch_seed=100 # 全局随机种子\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62361f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pipeline.backend.pipeline.PipeLine at 0x7f4b8936a2e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 添加组件到pipeline，定义数据IO关系，提交即可\n",
    "pipeline.add_component(reader_0)\n",
    "pipeline.add_component(nn_component, data=Data(train_data=reader_0.output.data))\n",
    "pipeline.add_component(Evaluation(name='eval_0', eval_type='multi'), data=Data(data=nn_component.output.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fa46219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-11-03 15:46:13.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mJob id is 202211031546128971780\n",
      "\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:13.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:00\u001b[0m\n",
      "\u001b[0mm2022-11-03 15:46:14.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2022-11-03 15:46:14.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:01\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:15.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:02\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:16.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:03\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:17.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:04\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:19.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:05\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:20.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:06\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:21.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:07\u001b[0m\n",
      "\u001b[0mm2022-11-03 15:46:23.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2022-11-03 15:46:23.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:09\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:24.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:10\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:25.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:12\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:26.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:13\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:27.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:14\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:29.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:15\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:30.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:16\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:31.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:17\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:32.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:18\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:33.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:19\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:34.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:20\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:35.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:21\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:36.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:23\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:37.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:24\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:38.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:25\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:40.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:26\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:41.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:27\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:42.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:28\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:43.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:29\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:44.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:30\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:45.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:32\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:46.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:33\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:47.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:34\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:48.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:35\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:50.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:36\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:51.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:37\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:52.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:38\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:53.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:39\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:54.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:41\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-11-03 15:46:55.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:42\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:57.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:43\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:58.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:44\u001b[0m\n",
      "\u001b[32m2022-11-03 15:46:59.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:46\u001b[0m\n",
      "\u001b[32m2022-11-03 15:47:00.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:47\u001b[0m\n",
      "\u001b[32m2022-11-03 15:47:01.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:48\u001b[0m\n",
      "\u001b[32m2022-11-03 15:47:03.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:49\u001b[0m\n",
      "\u001b[32m2022-11-03 15:47:04.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:50\u001b[0m\n",
      "\u001b[0mm2022-11-03 15:47:06.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2022-11-03 15:47:06.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:00:52\u001b[0m\n",
      "\u001b[32m2022-11-03 15:47:07.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:00:54\u001b[0m\n",
      "\u001b[32m2022-11-03 15:47:09.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:00:55\u001b[0m\n",
      "\u001b[32m2022-11-03 15:47:10.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:00:56\u001b[0m\n",
      "\u001b[32m2022-11-03 15:47:11.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:00:57\u001b[0m\n",
      "\u001b[32m2022-11-03 15:47:12.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:00:58\u001b[0m\n",
      "\u001b[32m2022-11-03 15:47:13.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:00:59\u001b[0m\n",
      "\u001b[32m2022-11-03 15:47:14.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:01:00\u001b[0m\n",
      "\u001b[32m2022-11-03 15:47:15.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:01:01\u001b[0m\n",
      "\u001b[32m2022-11-03 15:47:16.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:01:02\u001b[0m\n",
      "\u001b[32m2022-11-03 15:47:17.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component eval_0, time elapse: 0:01:03\u001b[0m\n",
      "\u001b[32m2022-11-03 15:47:19.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mJob is success!!! Job id is 202211031546128971780\u001b[0m\n",
      "\u001b[32m2022-11-03 15:47:19.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTotal time: 0:01:06\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pipeline.compile()\n",
    "pipeline.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5734f3",
   "metadata": {},
   "source": [
    "成功了！并且 我们可以用同样的方式，为任务加一个验证集，看看效果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3897be2",
   "metadata": {},
   "source": [
    "## 提交使用自定义模型的Homo-NN任务 + 验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac41557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-11-03 15:47:57.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mJob id is 202211031547562373210\n",
      "\u001b[0m\n",
      "\u001b[32m2022-11-03 15:47:57.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:00\u001b[0m\n",
      "\u001b[32m2022-11-03 15:47:58.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:01\u001b[0m\n",
      "\u001b[0mm2022-11-03 15:48:00.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2022-11-03 15:48:00.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:03\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:01.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:04\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:02.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:05\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:03.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:06\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:04.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:07\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:05.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:08\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:06.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:09\u001b[0m\n",
      "\u001b[0mm2022-11-03 15:48:09.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2022-11-03 15:48:09.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:12\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:10.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:13\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:11.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:14\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:12.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:15\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:13.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:16\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:14.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:17\u001b[0m\n",
      "\u001b[0mm2022-11-03 15:48:17.376\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2022-11-03 15:48:17.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:20\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:18.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:21\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:19.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:22\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:20.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:23\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:22.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:24\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:23.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:25\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:24.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:27\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:25.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:28\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:26.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:29\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:27.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:30\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:28.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:31\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:29.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:32\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:30.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:33\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:31.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:34\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:32.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:35\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:33.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:36\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:35.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:37\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:36.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:38\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:37.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:40\u001b[0m\n",
      "\u001b[32m2022-11-03 15:48:38.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:41\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "from torch import nn\n",
    "from pipeline import fate_torch_hook\n",
    "from pipeline.component import HomoNN\n",
    "from pipeline.backend.pipeline import PipeLine\n",
    "from pipeline.component import Reader, Evaluation, DataTransform\n",
    "from pipeline.interface import Data, Model\n",
    "\n",
    "fate_torch_hook(t)\n",
    "\n",
    "import os\n",
    "# 绑定地址到fate name&namespace\n",
    "fate_project_path = os.path.abspath('../')\n",
    "host_0 = 10000\n",
    "host_1 = 9999\n",
    "pipeline = PipeLine().set_initiator(role='host', party_id=host_0).set_roles(host=[host_0, host_1],\n",
    "                                                                            arbiter=[host_0])\n",
    "\n",
    "validate_data = {\"name\": \"mnist_validate\", \"namespace\": \"experiment\"}\n",
    "\n",
    "# 为方便，本示例中两个client使用同一份数据集\n",
    "data_path_val = fate_project_path + '/examples/data/mnist_val'\n",
    "pipeline.bind_table(name=validate_data['name'], namespace=validate_data['namespace'], path=data_path_val)\n",
    "\n",
    "# 定义reader\n",
    "reader_0 = Reader(name=\"reader_0\")\n",
    "reader_0.get_party_instance(role='host', party_id=host_0).component_param(table=data_0)\n",
    "reader_0.get_party_instance(role='host', party_id=host_1).component_param(table=data_1)\n",
    "# validate data\n",
    "reader_1 = Reader(name=\"reader_1\")\n",
    "reader_1.get_party_instance(role='host', party_id=host_0).component_param(table=validate_data)\n",
    "reader_1.get_party_instance(role='host', party_id=host_1).component_param(table=validate_data)\n",
    "\n",
    "from pipeline.component.homo_nn import DatasetParam, TrainerParam  # 数据集的接口\n",
    "from pipeline.component.nn.backend.torch.cust_model import CustModel  # 自定义模型的接口\n",
    "\n",
    "model = t.nn.Sequential(\n",
    "    t.nn.CustModel(name='image_net', class_num=10) # name指定自定义模型的模块名，name之外的参数将会被传递到模型的__init__上，比如\n",
    "                                                    # 此处的class_num\n",
    ")\n",
    "\n",
    "nn_component = HomoNN(name='nn_0',\n",
    "                      model=model, # 模型\n",
    "                      loss=t.nn.CrossEntropyLoss(),\n",
    "                      optimizer=t.optim.Adam(model.parameters(), lr=0.01),\n",
    "                      dataset=DatasetParam(dataset_name='image'),  # 使用image dataset\n",
    "                      trainer=TrainerParam(trainer_name='fedavg_trainer', epochs=3, batch_size=256, validation_freqs=1),\n",
    "                      torch_seed=100 # 全局随机种子\n",
    "                      )\n",
    "\n",
    "# 添加组件到pipeline，定义数据IO关系，提交即可\n",
    "pipeline.add_component(reader_0)\n",
    "pipeline.add_component(reader_1)\n",
    "pipeline.add_component(nn_component, data=Data(train_data=reader_0.output.data, validate_data=reader_1.output.data))\n",
    "pipeline.add_component(Evaluation(name='eval_0', eval_type='multi'), data=Data(data=nn_component.output.data))\n",
    "pipeline.compile()\n",
    "pipeline.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa914f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
